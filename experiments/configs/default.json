{
  "name": "Med-HALT RAG Default Experiment",
  "description": "Baseline vs MedGraphRAG comparison on Med-HALT benchmark",

  "results_dir": "results",

  "baseline": {
    "dataset": "data/raw/medhalt/test.jsonl",
    "model": "gpt-3.5-turbo",
    "provider": "openai",
    "mode": "zero-shot",
    "temperature": 0.1,
    "max_tokens": 500,
    "limit": null
  },

  "rag": {
    "dataset": "data/raw/medhalt/test.jsonl",
    "model": "gpt-3.5-turbo",
    "provider": "openai",
    "template": "strict",
    "temperature": 0.1,
    "max_tokens": 500,

    "index_dir": "index",
    "graph": "graph/graph.pkl",
    "neo4j_uri": null,

    "top_k": 10,
    "max_candidates": 100,
    "alpha": 0.5,
    "beta": 0.5
  },

  "evaluation": {
    "ground_truth": "data/raw/medhalt/test.jsonl",
    "correct_score": 1.0,
    "incorrect_penalty": -0.25,
    "abstain_score": 0.0
  },

  "notes": [
    "Default configuration for testing the full pipeline",
    "Set limit in baseline/rag for quick testing (e.g., 'limit': 100)",
    "Set neo4j_uri if using Neo4j instead of NetworkX graph",
    "Adjust alpha/beta for graph vs embedding weighting in retrieval",
    "Provider options: 'openai' (default) or 'gemini'",
    "For Gemini, use model names like 'gemini-pro' or 'gemini-1.5-pro'"
  ]
}
